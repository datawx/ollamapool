{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLLAMAPool WebUI Monitoring\n",
    "import os\n",
    "EndPoint_NodeStatus=os.environ.get('EndPoint_NodeStatus')\n",
    "\n",
    "#Assert if the environment variables are set\n",
    "if EndPoint_NodeStatus is None:\n",
    "    raise ValueError(\"EndPoint_NodeStatus is not set\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trimmed down NodeStatus class\n",
    "import json\n",
    "class NodeStatus():\n",
    "    \n",
    "    def from_json(self,json_str):\n",
    "        self.__dict__=json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Message Handling Loop\n",
    "import time\n",
    "from typing import List\n",
    "from azure.servicebus import ServiceBusClient, ServiceBusMessage\n",
    "\n",
    "# Replace with your connection string and queue name\n",
    "queue_name = \"node-status\"\n",
    "hosts_Status={}\n",
    "\n",
    "# Create a Service Bus client\n",
    "servicebus_client = ServiceBusClient.from_connection_string(conn_str=EndPoint_NodeStatus)\n",
    "\n",
    "def receive_messages_from_queue():\n",
    "    # Create a receiver for the queue\n",
    "    with servicebus_client.get_queue_receiver(queue_name=queue_name) as receiver:\n",
    "        print(\"Receiving messages from the queue...\")\n",
    "        \n",
    "        # Receive messages in a batch, you can specify max_message_count as needed\n",
    "        received_msgs = receiver.receive_messages(max_message_count=20, max_wait_time=30)\n",
    "\n",
    "        for msg in received_msgs:\n",
    "            # Print the message payload\n",
    "            print(f\"Received message: {str(msg)}\")\n",
    "            \n",
    "            #Update node status\n",
    "            nodeStatus=NodeStatus()\n",
    "            nodeStatus.from_json(str(msg))\n",
    "            hosts_Status[nodeStatus.Host]=nodeStatus\n",
    "            print(f\"Hosts Status: {hosts_Status}\")\n",
    "            #print(nodeStatus.to_json())\n",
    "            \n",
    "            # Accept the message to remove it from the queue\n",
    "            receiver.complete_message(msg)\n",
    "            \n",
    "\n",
    "#receive_messages_from_queue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.102:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "#Web Dash\n",
    "from flask import Flask, render_template\n",
    "from threading import Thread\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Example hosts_Status dictionary\n",
    "# hosts_Status = {\n",
    "#     \"host1\": {\"Host\": \"host1\", \"OllamaHost\": \"ollama1\", \"Status\": \"Online\", \"Message\": \"All good\", \"Models\": [\"model1\", \"model2\"], \"LastQueryTime\": 1234567890},\n",
    "#     \"host2\": {\"Host\": \"host2\", \"OllamaHost\": \"ollama2\", \"Status\": \"Offline\", \"Message\": \"Error\", \"Models\": [\"model3\"], \"LastQueryTime\": 1234567890}\n",
    "# }\n",
    "\n",
    "@app.route('/')\n",
    "def show_hosts():\n",
    "    return render_template('hosts.html', hosts_status=hosts_Status)\n",
    "\n",
    "# Thread to run Flask in Jupyter\n",
    "def run_app():\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "\n",
    "# Running Flask in a separate thread\n",
    "flask_thread = Thread(target=run_app)\n",
    "flask_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Initializing...\", \"Message\": \"\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DD460>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DDA30>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processingdcbac0e5-dbc0-42cf-ad3a-9f2285bc7d8c\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DDA60>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processingdcbac0e5-dbc0-42cf-ad3a-9f2285bc7d8c\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 16.466405}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DDA90>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processingcb5ed045-093a-4016-b9a7-6b50a7994b28\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 16.466405}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DDAC0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processingcb5ed045-093a-4016-b9a7-6b50a7994b28\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.324704}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DDB50>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing4268ca6e-ab4d-4057-a221-12de15edf808\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.324704}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F29D0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing4268ca6e-ab4d-4057-a221-12de15edf808\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 4.915932}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F2EE0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing3ea2458a-b604-4b2c-905b-ed8bf19bf1a6\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 4.915932}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F21C0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing3ea2458a-b604-4b2c-905b-ed8bf19bf1a6\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 4.905937}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572BE7F0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing0d7ebf66-e1f7-4d7f-b806-d03f2301fe70\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 4.905937}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0573324F0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing0d7ebf66-e1f7-4d7f-b806-d03f2301fe70\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.36672}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DD520>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing0a354cf1-4612-4060-acc3-e27b83d872ef\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.36672}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0573327F0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing0a354cf1-4612-4060-acc3-e27b83d872ef\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.397741}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057332C70>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing9bc2d7f4-14f3-4263-bc3c-f1081dc2e126\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.397741}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F23A0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing9bc2d7f4-14f3-4263-bc3c-f1081dc2e126\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 7.580792}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731CEB0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processingb25e42d6-2abe-48c8-a746-17ef86cd608b\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 7.580792}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337790>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processingb25e42d6-2abe-48c8-a746-17ef86cd608b\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.469183}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732C250>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processingc9db157d-1f75-4324-a34e-bc74ed34585f\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.469183}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337190>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processingc9db157d-1f75-4324-a34e-bc74ed34585f\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.119837}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F2B50>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing4bdd9901-802b-4a6f-8730-6a93300d41dd\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.119837}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F2EE0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing4bdd9901-802b-4a6f-8730-6a93300d41dd\", \"Models\": [\"llama3.1:latest\"], \"LastQueryTime\": 5.33782}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C850>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337C10>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0573613D0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing12775d03-22c0-402a-b000-544ef8542af4\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057332BE0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing12775d03-22c0-402a-b000-544ef8542af4\", \"Models\": [], \"LastQueryTime\": 7.383851}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337790>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processinga89011f0-e044-4381-8eb2-4cfc399f18f9\", \"Models\": [], \"LastQueryTime\": 7.383851}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732CD60>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processinga89011f0-e044-4381-8eb2-4cfc399f18f9\", \"Models\": [], \"LastQueryTime\": 4.187377}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732C1C0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing6808e544-475e-44d6-86b3-0fa0be810f9f\", \"Models\": [], \"LastQueryTime\": 4.187377}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337AC0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing6808e544-475e-44d6-86b3-0fa0be810f9f\", \"Models\": [], \"LastQueryTime\": 6.18207}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057332280>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing4c4dd04e-bc2b-4829-900d-374b8b87bd06\", \"Models\": [], \"LastQueryTime\": 6.18207}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337250>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing4c4dd04e-bc2b-4829-900d-374b8b87bd06\", \"Models\": [], \"LastQueryTime\": 5.886788}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DDDF0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing7b37483b-196d-4e41-a7ea-97dffd765685\", \"Models\": [], \"LastQueryTime\": 5.886788}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057370D60>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing7b37483b-196d-4e41-a7ea-97dffd765685\", \"Models\": [], \"LastQueryTime\": 5.260424}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C850>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing8ab30491-e979-4a35-adae-b320b7bb4726\", \"Models\": [], \"LastQueryTime\": 5.260424}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732CD30>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing8ab30491-e979-4a35-adae-b320b7bb4726\", \"Models\": [], \"LastQueryTime\": 7.301731}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05736F940>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing444958cc-6895-4e8f-a8e5-55fc47bfbf97\", \"Models\": [], \"LastQueryTime\": 7.301731}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057370D90>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing444958cc-6895-4e8f-a8e5-55fc47bfbf97\", \"Models\": [], \"LastQueryTime\": 5.390963}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361AC0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processinga831677a-9383-4127-aa28-c3a7b4b9f089\", \"Models\": [], \"LastQueryTime\": 5.390963}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361550>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processinga831677a-9383-4127-aa28-c3a7b4b9f089\", \"Models\": [], \"LastQueryTime\": 5.664428}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355FD0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processinge9e865b5-be1f-424c-9db8-a14a92ffad12\", \"Models\": [], \"LastQueryTime\": 5.664428}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355700>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processinge9e865b5-be1f-424c-9db8-a14a92ffad12\", \"Models\": [], \"LastQueryTime\": 5.151125}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572BE850>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361700>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057370100>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572BE250>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Shutdown\", \"Message\": \"Shut Down Complete\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DD9D0>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732CE20>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Shutdown\", \"Message\": \"Shut Down Complete\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057370A60>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355E80>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731CA30>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Error\", \"Message\": \"Error Processing9aa8aa5e-daec-4425-8b3f-628740b6100a: 'Client' object has no attribute 'download'\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355E80>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C820>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Error\", \"Message\": \"Error Processing25cce2ee-1aba-4352-bc12-45800ddf2c7a: 'Client' object has no attribute 'download'\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355E80>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732CE20>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Error\", \"Message\": \"Error Processingc9e1aa17-d3a8-407c-ac78-9562e362ea7c: 'Client' object has no attribute 'download'\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355E80>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F25B0>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Error\", \"Message\": \"Error Processing179af21b-8964-4cfd-b198-b1c25c36097c: 'Client' object has no attribute 'download'\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355E80>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732C790>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Error\", \"Message\": \"Error Processingcba2ca0b-d058-434b-aa3b-af85c5bb4514: 'Client' object has no attribute 'download'\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732C520>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C4C0>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Error\", \"Message\": \"Error Processingd5ba4ead-844b-4b82-877c-1c267f0e3353: 'Client' object has no attribute 'download'\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05732C520>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Shutdown\", \"Message\": \"Shut Down Complete\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572BEC70>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Waiting for Queries\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361EB0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361970>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057332160>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processingb3f89339-e629-4c4c-bafc-3d17d955d149\", \"Models\": [], \"LastQueryTime\": 0}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361970>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processingb3f89339-e629-4c4c-bafc-3d17d955d149\", \"Models\": [], \"LastQueryTime\": 35.007825}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C100>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 35.007825}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F2A00>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 35.007825}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C100>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing05fa17ae-0c44-4f51-9c55-c47ce4663e26\", \"Models\": [], \"LastQueryTime\": 35.007825}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F27C0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing05fa17ae-0c44-4f51-9c55-c47ce4663e26\", \"Models\": [], \"LastQueryTime\": 22.217043}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F2B20>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 22.217043}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355130>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 22.217043}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361880>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing7e451835-16a5-4b59-884a-2ff33c7c8ced\", \"Models\": [], \"LastQueryTime\": 22.217043}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355130>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing7e451835-16a5-4b59-884a-2ff33c7c8ced\", \"Models\": [], \"LastQueryTime\": 13.297574}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0573611C0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 13.297574}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361340>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 13.297574}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361730>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing44653832-4fd8-400b-8a16-f437c4630f6c\", \"Models\": [], \"LastQueryTime\": 13.297574}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361550>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing44653832-4fd8-400b-8a16-f437c4630f6c\", \"Models\": [], \"LastQueryTime\": 25.737457}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355F40>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 25.737457}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337250>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 25.737457}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057332730>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing6bdea878-7bcc-4f3d-b979-f0ba610d7091\", \"Models\": [], \"LastQueryTime\": 25.737457}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057332130>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing6bdea878-7bcc-4f3d-b979-f0ba610d7091\", \"Models\": [], \"LastQueryTime\": 26.645666}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C490>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 26.645666}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F20A0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 26.645666}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355280>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing71d41245-ee9b-44e9-b082-c01eff7f3a6c\", \"Models\": [], \"LastQueryTime\": 26.645666}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F20A0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing71d41245-ee9b-44e9-b082-c01eff7f3a6c\", \"Models\": [], \"LastQueryTime\": 13.592249}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361AC0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 13.592249}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361580>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 13.592249}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337C10>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processingf013cea8-0ec3-4af6-9a5f-73fc1078d8e2\", \"Models\": [], \"LastQueryTime\": 13.592249}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361580>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processingf013cea8-0ec3-4af6-9a5f-73fc1078d8e2\", \"Models\": [], \"LastQueryTime\": 19.682357}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337C40>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 19.682357}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0573556A0>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 19.682357}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337C40>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing249c0b7f-8f1c-429c-87c5-fb340af9dd74\", \"Models\": [], \"LastQueryTime\": 19.682357}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361FA0>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing249c0b7f-8f1c-429c-87c5-fb340af9dd74\", \"Models\": [], \"LastQueryTime\": 32.653728}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572BE880>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 32.653728}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C100>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 32.653728}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DDD00>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing9d70d4c3-84ed-4374-8818-6d690b0f9b2a\", \"Models\": [], \"LastQueryTime\": 32.653728}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05731C100>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing9d70d4c3-84ed-4374-8818-6d690b0f9b2a\", \"Models\": [], \"LastQueryTime\": 25.637765}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05736F820>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 25.637765}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DD880>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 25.637765}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572BE7F0>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing8e8de587-e725-42d2-851a-faf7722d19af\", \"Models\": [], \"LastQueryTime\": 25.637765}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572DD880>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing8e8de587-e725-42d2-851a-faf7722d19af\", \"Models\": [], \"LastQueryTime\": 17.813903}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F2550>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 17.813903}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355B50>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 17.813903}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361BB0>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing8596841b-df89-4822-bb6a-73d2e8918bcc\", \"Models\": [], \"LastQueryTime\": 17.813903}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057355B50>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing8596841b-df89-4822-bb6a-73d2e8918bcc\", \"Models\": [], \"LastQueryTime\": 18.996032}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05736F430>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 18.996032}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05736FA60>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 18.996032}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05736F790>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processingfc124937-8d17-43e5-9671-d90c278bcde6\", \"Models\": [], \"LastQueryTime\": 18.996032}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B05736FB50>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processingfc124937-8d17-43e5-9671-d90c278bcde6\", \"Models\": [], \"LastQueryTime\": 19.344907}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0573378B0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 19.344907}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337B80>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 19.344907}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057332D60>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processinga082448a-2789-402e-bad6-98673ef8f8fd\", \"Models\": [], \"LastQueryTime\": 19.344907}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337B80>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processinga082448a-2789-402e-bad6-98673ef8f8fd\", \"Models\": [], \"LastQueryTime\": 18.583331}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0573322B0>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Downloading\", \"Message\": \"Downloading Model mistral-small\", \"Models\": [], \"LastQueryTime\": 18.583331}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361880>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Ready\", \"Message\": \"Model mistral-small Downloaded\", \"Models\": [], \"LastQueryTime\": 18.583331}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B0572F2A60>}\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Running\", \"Message\": \"Processing1a4835f6-e8fc-4300-b115-78d5dee1e18d\", \"Models\": [], \"LastQueryTime\": 18.583331}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361880>}\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Finsihed\", \"Message\": \"Processing1a4835f6-e8fc-4300-b115-78d5dee1e18d\", \"Models\": [], \"LastQueryTime\": 19.297211}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057361820>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Received message: {\"Host\": \"Euclid\", \"OllamaHost\": \"http://localhost:11434\", \"Status\": \"Shutdown\", \"Message\": \"Shut Down Complete\", \"Models\": [], \"LastQueryTime\": 19.297211}\n",
      "Hosts Status: {'Euclid': <__main__.NodeStatus object at 0x000001B057337790>}\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n",
      "Receiving messages from the queue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.102 - - [23/Sep/2024 20:37:50] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:37:50] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:37:51] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:37:53] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:37:54] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:37:56] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:37:57] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:37:58] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:37:59] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:01] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:01] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:02] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:02] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:03] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:03] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:03] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:04] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:04] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:05] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:05] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:06] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:06] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:07] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:07] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:08] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:08] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:44] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:38:46] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:02] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:04] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:04] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:04] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:06] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:06] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:07] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:07] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:07] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 20:39:09] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:02:47] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:06] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:08] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:09] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:09] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:10] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:10] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:10] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:11] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:11] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:12] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:13] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:14] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:15] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:15] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:16] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:16] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:17] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:17] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:18] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:19] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:19] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:20] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:20] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:21] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:21] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:22] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:22] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:22] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:23] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:23] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:23] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:24] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:24] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:23:24] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:24:18] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:24:28] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:34:31] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:34:32] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:35:08] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:36:34] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:36:43] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:36:46] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:36:47] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:36:49] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:36:50] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:41:39] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:41:49] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:44:09] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:50:49] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:50:50] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:50:51] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:50:52] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.102 - - [23/Sep/2024 21:50:55] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    receive_messages_from_queue()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
